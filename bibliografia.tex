\documentclass{article}
\usepackage{amsmath}
\usepackage{bm} % Bold math
\usepackage{amssymb} 
\usepackage{hyperref} % References and url
\usepackage{graphicx} % To insert images
\usepackage{listings} % To insert code
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }

 \graphicspath{ {./figures/} }

\title{Model Order Reduction for linear structural dynamics}
\author{Miguel Calpe Linares}
\date{}

\begin{document}
\maketitle

The governing equation of a linear structural dynamic system is
\begin{equation}
    \bm{M}\bm{\ddot{u}} + \bm{K}\bm{u} = \bm{0},
    \label{eq:linear_equation}
\end{equation}
where $\bm{M}$ is the mass matrix and $\bm{K}$ is the stiffness matrix. Since all 
the operators are linear, we can find an operator $\bm{V}$ such that 
\begin{equation}
    \bm{V}^T\bm{M}\bm{V}\bm{\ddot{q}} + \bm{V}^T\bm{K}\bm{V}\bm{q} = \bm{0},
    \label{eq:reduced_linear_equation}
\end{equation}
where $\bm{M}_r=\bm{V}^T\bm{M}\bm{V}$ and $\bm{K}_r=\bm{V}^T\bm{K}\bm{V}$ are the reduced mass and 
stiffness matrix. The equation \ref{eq:reduced_linear_equation} is a linear independent 
system of equations with a reduced order $r$.\newline

Goal: compute operator $\bm{V}$.\newline

\textbf{List of methods}

\begin{center}
  \begin{tabular}{||c c c ||} 
  \hline
  Method & linear/non-linear & Model \\ [0.5ex] 
  \hline\hline
  Modal truncation & Linear systems & Theory-based \\ 
  \hline
  Krylov & Linear (force inputs) & Theory-based \\ 
  \hline
  POD & Non-linear \& linear & Data-based \\ 
  \hline
 \end{tabular}
 \end{center}

\section{Modal truncation}
Source: see references \cite{rutzmoser18}. \newline 

In the modal truncation approach, the operator $\bm{V}$ is composed of a selected  
eigenmodes of the system \ref{eq:linear_equation}.\newline

Considering the analytical solution for the equation \ref{eq:linear_equation} such as
\begin{equation}
    \bm{u}(t) = \bm{\phi}_i \cos (\omega_it + \alpha),
\end{equation}

we obtain the generalized eigenvalue problem
\begin{equation}
    \omega_i^2 \bm{M}\bm{\phi}_i = \bm{K}\bm{\phi}_i,
\end{equation}
where $\omega_i$ are the eigenfrequencies and $\bm{\phi}_i$ are the eigenvectors of the system.\newline

We fix the norm of the eigenvector to be one $\bm{\phi}_i^T \bm{M} \bm{\phi}_i=1$.\newline

We gather all the eigenvectors in the matrix $\bm{\Phi} = [\bm{\phi}_1,..., \bm{\phi}_N]$. 
We apply the operator $\bm{\phi}$ to the mass and stiffness matrices and we obtain
\begin{align*}
% \bm{\Phi}^T \bm{M} \bm{\Phi}&=\bm{I} & \bm{\Phi}^T \bm{K} \bm{\Phi}=0\\
\bm{\Phi}^T \bm{M} \bm{\Phi}&=\bm{I} & \bm{\Phi}^T \bm{K} \bm{\Phi}=\begin{bmatrix}
    \omega_1^2 & 0 & 0\\
    0 & \ddots & 0 \\
    0 & 0 & \omega_N^2
  \end{bmatrix}.
\end{align*}

Using the basis $\bm{\Phi}$, the system \ref{eq:reduced_linear_equation} decouples into
\begin{equation}
    \begin{bmatrix}
        \ddot{q_1} \\
        \vdots\\
        \ddot{q_N}
      \end{bmatrix} + 
      \begin{bmatrix}
        \omega_1^2 & 0 & 0\\
        0 & \ddots & 0 \\
        0 & 0 & \omega_N^2
      \end{bmatrix} \begin{bmatrix}
        q_1 \\
        \vdots\\
        q_N
      \end{bmatrix} = 
      \begin{bmatrix}
        0\\
        \vdots\\
        0
      \end{bmatrix}.
\end{equation}
Projecting the system of equations in the basis $\bm{\Phi}$ results in decoupled system with 
N independent ODE's.\newline

In modal truncation, the full basis $\bm{\Phi}$ is truncated , so that $\bm{V}$ is only composed of 
of a selection of vibration modes $\bm{\phi}_i$. \newline

\textbf{Selection Criteria}
\begin{enumerate}
    \item Proposed by Geradin and Rixen 2014. Truncate eigenmodes $\bm{\phi}_i$ with eigenfrequencies $\omega_i$ up to twice the highest frequency of interest. 
    \item Excite one degree of freedom. Choose the most energetic eigenmodes. 
\end{enumerate}

Computation of the eigenmodes: power iteration methods with combination with Lanczos iterations.

\section{Krylov subspace reduction}

It builds a basis with the knowledge of the force input locations.\newline

The external force vector $\bm{g}$ can be expressed as the product of the constant location matrix 
$\bm{G} \in \mathbb{R}^{N \times p}$ and the time dependent amplitude $\hat{\bm{g}}(t) \in \mathbb{R}^p$.\newline

Key: build a basis $\bm{V}$ with the static displacements and higher order approximations. \newline

We consider the linear equations of motions
\begin{equation}
  \bm{M}\bm{\ddot{u}} + \bm{K}\bm{u} = \bm{G}\hat{\bm{g}}. 
  \label{eq:krylov_subspace_reduction}
\end{equation}

We consider $\bm{u}=\bm{v_1}$ to be a first approximation solution of the equation \ref{eq:krylov_subspace_reduction}. 
As a first approximation, the acceleration term $\bm{M}\bm{\ddot{v}_1}$ cancels out. We obtain 
\begin{equation}
\bm{v}_1 = \bm{K}^{-1}\bm{G}\hat{\bm{g}}
\end{equation}

The first element of the Krylov basis is
\begin{equation}
  \bm{v}_{1, kry} = \bm{K}^{-1}\bm{G}
  \end{equation}

We can consider now $\bm{u}=\bm{v_1} + \bm{v_2}$ and insert to equation \ref{eq:krylov_subspace_reduction}
\begin{equation}
  \bm{M}(\bm{\ddot{v}_1} + \bm{\ddot{v}_2}) + \bm{K}(\bm{v}_1 + \bm{v}_2) = \bm{G}\hat{\bm{g}},
  \label{eq:krylov_subspace_reduction}
\end{equation}

leading to 
\begin{equation}
  \bm{v}_{2, kry} = \bm{K}^{-1}\bm{M}\bm{v}_{1, kry} = \bm{K}^{-1}\bm{M}\bm{K}^{-1}\bm{G}.
  \end{equation}

This procedure can be repeated m times leading to the raw Krylov basis 
\begin{equation}
\bm{V}_{kry} = (\bm{K}^{-1}\bm{G}, \bm{K}^{-1}\bm{M}\bm{K}^{-1}\bm{G}, \ddots , (\bm{K}^{-1}\bm{M})^{m-1}\bm{K}^{-1}\bm{G})
\end{equation}

The linear independence between the elements of the basis is very poor. Orthogonalization
shoud be done at each element computation with respect all previous Krylov vectors. This orthogonalization
is known as Arnoldi and Lanzcos iteration (see \cite{geradin14}). \newline

Modal Truncation Augmentation combine the advantages of modal truncation method and 
Krylov subspace reduction. 

\section{Proper Orthogonal Decomposition}
Proper Orthogonal decomposition is applied in fluid mechanics \cite{weiss19,lassila14,taira17,berkooz13} and in structural mechanics \cite{thiene11, feeny98} \newline


Appropiate to non-linear systems. \newline

Data-driven method: training simulations $\rightarrow$ analysis of the results $\rightarrow$ build 
projection matrix $V$.\newline

Used in fluid dynamics, damage detection and strutural dynamics.\newline

We consider a marix with n samples and m observations as
\begin{equation}
  \bm{S} =
  \begin{bmatrix}
      u_1(t_1) \cdots u_n(t_1)\\
      \vdots\\
      u_1(t_m) \cdots u_n(t_m)\\
    \end{bmatrix} 
    .
\end{equation}

We extract the mean of each element of the matrix $u_i(t_j)' = u_i(t_j) - \hat{u}$ and 
we obtain the matrix 
\begin{equation}
  \bm{U} =
  \begin{bmatrix}
      u_1'(t_1) \cdots u_n'(t_1)\\
      \vdots\\
      u_1'(t_m) \cdots u_n'(t_m)\\
    \end{bmatrix} 
    .
\end{equation}

We can compute the covariance matrix as 
\begin{equation}
  \bm{C} = \frac{1}{m-1}\bm{U}^T\bm{U} = \frac{1}{m-1}
  \begin{bmatrix}
      \sum_{i=1}^{m} u_1'(t_1) \cdots \sum_{i=1}^{m} u_n'(t_1)\\
      \vdots\\
      \sum_{i=1}^{m} u_1'(t_m) \cdots \sum_{i=1}^{m} u_n'(t_m)\\
    \end{bmatrix} 
    .
\end{equation}

The proper orthogonal basis is formed with the vectors which maximizes the variance (representation of the data) and the covariance between vectors 
should be ideally zero. In order to compute this proper orthogonal basis, we compute the eigenvectors of the covariance matrix. \newline
We compute the eigenvectors and eigenvalues of matrix $\bm{C}$. Since $\bm{C}$ is symmetric,
the eigenvectors necessarly form a orthonormal basis in which $\bm{C}$ can be diagonalized. 
Formally, the covariance matrix is diagonalized as 
\begin{equation}
  \bm{C} = \bm{\Phi}\bm{\Lambda}\bm{\Phi}^{-1} = \bm{\Phi}\bm{\Lambda}\bm{\Phi}^T =
  \begin{bmatrix}
    \phi_{11} \cdots \phi_{1n}\\
    \vdots\\
    \phi_{m1} \cdots \phi_{mn}\\
  \end{bmatrix} 
    \begin{bmatrix}
    \lambda_{11} \cdots \lambda_{1n}\\
    \vdots\\
    \lambda_{m1} \cdots \lambda_{mn}\\
  \end{bmatrix} 
  \begin{bmatrix}
    \phi_{11} \cdots \phi_{n1}\\
    \vdots\\
    \phi_{1m} \cdots \phi_{nm}\\
  \end{bmatrix} 
  ,
\end{equation}
where the columns of $\bm{\Phi}$ are the eigenvectors of $\bm{C}$.\newline

We can project the original dataset $\bm{U}$ onto each of the n modes as 
\begin{equation}
  \bm{A} = \bm{U}\bm{\Phi} =
  \begin{bmatrix}
    a_{11} \cdots a_{1n}\\
    \vdots\\
    a_{m1} \cdots a_{mn}\\
  \end{bmatrix}
  = 
  \begin{bmatrix}
    u_1'(t_1) \cdots u_n'(t_1)\\
    \vdots\\
    u_1'(t_m) \cdots u_n'(t_m)\\
  \end{bmatrix} 
  \begin{bmatrix}
    \phi_{11} \cdots \phi_{1n}\\
    \vdots\\
    \phi_{m1} \cdots \phi_{mn}\\
  \end{bmatrix} 
  ,
\end{equation}
where $a_{ij}$ is the projection of the data measured at time i onto the mode j. \newline

We can express the dataset $\bm{U}$ as the sum of the contributions from n modes as 
$\bm{U} = \bm{A} \bm{\Phi}^T$ as
\begin{equation}
  \begin{bmatrix}
    u_1'(t_1) \cdots u_n'(t_1)\\
    \vdots\\
    u_1'(t_m) \cdots u_n'(t_m)\\
  \end{bmatrix} 
  =
  \begin{bmatrix}
    a_{11}\\
    \vdots\\
    a_{m1}\\
  \end{bmatrix} 
  \begin{bmatrix}
    \phi_{11} \cdots \phi_{n1}\\
  \end{bmatrix}
  +
  \cdots 
  +
  \begin{bmatrix}
    a_{1n}\\
    \vdots\\
    a_{mn}\\
  \end{bmatrix} 
  \begin{bmatrix}
    \phi_{1n} \cdots \phi_{nn}\\
  \end{bmatrix}
  \simeq \sum_{k=1}^n\bm{\tilde{U}}^k.
\end{equation}

We have decomposed our original dataset into a sum of n contributions from n proper 
orthogonal modes.\newline

When the dimension $n \gg m$ (the number of samples is larger than the number of measurements), the dimension of the covariance matrix is $n \times n$, which is very large. We can apply the \textbf{SNAPSHOT POD} approach. The  covariance matrix will be with a size $m \times m$. \newline

\textbf{GALERKIN PROJECTION}. Model reduction via POD can also be used to generate a set of ordinary diferential equations (a fnite-dimensional dynamical system) as a simplifcation of the partial diferential equations normally used to solve fuid-mechanics problems.

\section{Randomized Singular Value Decomposition (rSVD)}

KRATOS framework uses the rSVD approach and it is based on the reference \cite{halko10}.\newline

Python implementation with a good explanation: \url{https://towardsdatascience.com/intuitive-understanding-of-randomized-singular-value-decomposition-9389e27cb9de}.\newline

More references of the rSVD with good explanation are in \cite{erichson16}.\newline

Key: Compute a low-rank approximation to a given matrix $\bm{A}$\newline

The low-approximation is performed through Singular Value Decomposition with a randomized algorithm.\newline

The Singular Value Decomposition of a given marix $\bm{A}$ is
\begin{equation}
  \bm{A} = \bm{U}\bm{\Sigma}\bm{V}^*.
\end{equation}

The steps to perform a randomized SVD to matrix $\bm{A} \in \mathbb{R}^{m \times n}$ are:

1. We generate a Gaussian random matrix $\bm{\Omega} \in \mathbb{R}^{n \times k}$ with $k<m,n$.

2. Compute the new matrix $\bm{Y} = \bm{A}\bm{\Omega} \in \mathbb{R}^{m \times k}$

3. Apply the QR decomposition to $\bm{Y} = \bm{Q} \bm{R}$ where $\bm{Q} \in \mathbb{R}^{m \times k}$ and $\bm{R} \in \mathbb{R}^{k \times k}$. $\bm{Q}$ is an orthogonal matrix. 

\begin{figure}[h!]
  \begin{center}
  \includegraphics[width=0.6 \linewidth]{rsvd_orthogonal_basis.png}
  \caption{Obtention of the orthogonal matrix $\bm{Q}$.}
  \label{fig:rsvd_orthogonal_basis}
  \end{center}
\end{figure}

4. Compute a new matrix as $\bm{B} = \bm{Q}^*\bm{A} \in \mathbb{R}^{k \times n}$.

5. Apply the SVD to $\bm{B}$ which is smaller than $\bm{A}$. $\bm{B} = \bm{\tilde{U}}\bm{\Sigma}\bm{V}^*$

6. We can compute the left eigenvectors as $\bm{U} = \bm{Q}\bm{\tilde{U}}$

\begin{figure}[h!]
  \begin{center}
  \includegraphics[width=0.6 \linewidth]{rsvd_factorization.png}
  \caption{Factorization of a low-order matrix $\bm{B}$.}
  \label{fig:factorization}
  \end{center}
\end{figure}

\section{Artículos Joaquín Alberto Hernández}

\subsection{Model reduction techniques in multiscale homogenization. \cite{hernandez14}}
Input of interest (strain tensor) $\rightarrow$ FE analysis (snapshots matrix) $\rightarrow$ dimensionality reduction (POD modes).\newline

Evaluation of integrals in p sampling points (reduced space $n_u$). Where to choose the sampling points? How to choose the weighting functions? \newline

Model reduction approaches: (in both, the integrand is approximated by a linear combination of the reduced set of empirical modes)
\begin{itemize}
  \item Interpolatory methods: coefficients are obtained by interpolation of a pre-selected sampling points by \textit{minimization interpolation error}
  \item Election of the sampling points and weights by \textit{minimization integration error}
\end{itemize}

Method to find POD modes of the displacements snapshots matrix $\bm{X_u}$ \newline

The basis of the reduced order model will be such that
\begin{equation}
  \mathbb{V}_{u}^{snp} = \mathbb{V}_{u,el}^{snp} \oplus \mathbb{V}_{u,inel}^{snp},
\end{equation}

the sum of POD elastic modes and inelastic modes.\newline

The procedure is the following:

1. Linear elastic FE analysis to get the displacement fields

2. Apply the POD method to obtain the reduced elastic basis $\mathbb{V}_{u,el}^{snp} = \{ \Phi_1, \cdots, \Phi_{me} \}$

3. Compute the inelastic displacements field such that $u_{inel}^k = u^k - \sum_{i=1}^{m_e} <\Phi_i u^k> \Phi_i$

4. Apply the POD method to $u_{inel}^k$ to compute the reduced basis of the inelastic regime $\mathbb{V}_{u,inel}^{snp} = \{ \Phi_{m_e+1}, \cdots, \Phi_{n_u} \}$

\subsection{Hyper-reduction of nonlinear finite element models via empirical cubature. \cite{hernandez17}}

The finite element semi-discrete motion equation we want to reduce is
\begin{equation}
  \bm{M^h} \bm{\ddot{d}}^h(\bm{\mu}) + \bm{F}^h(\bm{d}^h, \bm{d}_0^h; \bm{\mu}) = \bm{F}_{ext} \bm{\mu} - \bm{M}_0^h \bm{\ddot{d}}_0^h(\bm{\mu})
\end{equation}

\subsubsection{First reduction stage}
Goal: obtain few global basis vectors.

1. Solve FE problem with representative input parameter $\{\bm{\mu}^i\}_{i=1}^P$.

2. Store the vectors: unrestricted nodal displacements $\bm{d}^h$, prescribed nodal displacements $\bm{d}_0^h$ and external nodal forces $\bm{F}^h_{ext}$ into the snapshot matrices $\bm{X}_d$, $\bm{X}_{d_0}$ and $\bm{X}_{F_ext}$.

3. Apply the SVD to the snapshotmatrices $\bm{X}_d$, $\bm{X}_{d_0}$ and $\bm{X}_{F_ext}$ and obtain the reduced basis $\bm{\Phi} \in \mathbb{R}^{N \times n}$, $\bm{\Xi} \in \mathbb{R}^{N_0 \times n_0}$ and $\bm{\Theta} \in \mathbb{R}^{N \times n_f}$. We can apply the elastic/inelastic mode decomposition as in \cite{hernandez14}.

4. Determine interpolation indices $b \subseteq \{1, \hdots, N_0 \}$ and $c \subseteq \{1, \hdots, N \}$ corresponding to basis matrices $\bm{\Xi}$ and $\bm{\Theta}$ by Discrete Empirical Interpolation Method (DEIM).

5. Compute the reduced order matrices $\bm{\Phi}_0 = \bm{\Xi} \bm{\Xi}_b^{-1}$, $\bm{M} = \bm{\Phi}^T \bm{M}^h\bm{\Phi}$, $\bm{M}_0 = \bm{\Phi}^T \bm{M}_0^h\bm{\Phi}_0$, $\bm{R}_{ext} = \bm{\Phi}^T \bm{\Theta}\bm{\Theta}_0^{-1}$, $\bm{u}_0 = \bm{\Phi}^T \bm{u}_0^h$ and $\bm{v}_0 = \bm{\Phi}^T \bm{v}_0^h$. We obtain thus

\begin{equation}
  (\bm{\Phi}^T \bm{M^h}\bm{\Phi}) \bm{\ddot{d}}^h(\bm{\mu}) + \bm{\Phi}^T \bm{F}^h(\bm{d}^h, \bm{d}_0^h; \bm{\mu}) = \bm{\Phi}^T \bm{F}_{ext} \bm{\mu} - (\bm{\Phi}^T \bm{M}_0^h \bm{\Phi}) \bm{\ddot{d}}_0^h(\bm{\mu}).
\end{equation}

We can thus rewrite the equation as 
\begin{equation}
  \bm{M} \bm{\ddot{d}} + \bm{F} = \bm{F}_{ext} - \bm{M}_0 \bm{\ddot{d}}_0.
\end{equation}

where $\bm{F}$ is the nodal vector of the internal forces. It still depends of the mesh points M (M integration points). $\bm{F}$ can be written as
\begin{equation}
  \bm{F} = \int_\Omega f d\Omega \approx \sum_{g=1}^M W_g f(x_g)
\end{equation}

Goal: reduce the number of integration points from M to m ($m \ll M$). The question is how to choose the integration points? How to compute its associated weights?

\newpage
\section{Modal analysis undamped free vibrations}
In this section, I perform a modal analysis of a undamped free vibrating structure. We consider the following equation of motion
\begin{equation}
  \bm{M}\bm{\ddot{u}} + \bm{K}\bm{u} = 0.
  \label{eq:modal_analysis_motion_equation}
\end{equation}

We consider a solution such that
\begin{equation}
  \bm{u} = \bm{\phi} e^{i \omega t}.
\end{equation}

The acceleration is thus written as
\begin{equation}
  \bm{\ddot{u}} = -\omega^2 \bm{\phi} e^{i \omega t}.
\end{equation}

Introducing $\bm{u}$ qnd $\bm{\ddot{u}}$ into the equation \ref{eq:modal_analysis_motion_equation} we obtain the following expression
\begin{equation}
  (\bm{K} - \omega^2 \bm{M}) \bm{\phi} = 0.
\end{equation}

The solution $\bm{\phi} = 0$ is trivial. We are interested in solutions with $\bm{\phi} \neq 0$. We can thus write the above expression as
\begin{equation}
  (\bm{M}^{-1}\bm{K})\bm{\phi} = \omega^2 \bm{\phi},
\end{equation}
where $\bm{\phi}$ are the eigenvectors and $\lambda = \omega^2$ are the eigenvalues of the operator $\bm{M}^{-1}\bm{K}$. 

\subsection*{Validation rSVD of Kratos}
This section compares the displacement of one node and the displacement of the node reconstructed with rSVD tools of KRATOS.\newline

I have performed a modal analysis of a free cantilever beam with RamSeries. I computed the first 10 eigenmodes $\{\bm{\phi}_1, \dots, \bm{\phi}_{10}\}$ and the 10 eigenfrequencies $\{ \omega_1, \dots, \omega_{10} \}$.\newline

\noindent \textbf{case: 1 mode}

I construct the snapshot matrix with displacement field computed with the 1st mode and natural frequency such as 
\begin{equation}
  \bm{X}_d = \bm{\phi}_1 e^{i \omega_1 t}.
\end{equation}

I apply the Kratos tools to compute the rSVD of $\bm{X}_d$. I obtain $\sigma_1$, $\bm{\phi}'_1$ and $\bm{\theta}'_1$.\newline

The displacement of the node should be the same as the reconstructed with the rSVD such that
\begin{equation}
  \bm{\phi}_1 e^{i \omega_1 t} = \sigma_1 \bm{\phi}'_1 \bm{\theta}^{'T}_1. 
\end{equation}

\noindent \textbf{case: n-modes}

The displacement constructed with n linear modes should be the same as the reconstructed with the rSVD such that 

\begin{equation}
  \sum_{i=1}^n \bm{\phi}_i e^{i \omega_i t} = \sum_{i=1}^n \bm{\sigma}_i \bm{\phi}'_i \bm{\theta}^{'T}_i. 
\end{equation}


\newpage
\section{Tolerance in Kratos}
The class RandomizedSingularValueDecomposition computes the rSVD of a snapshot matrix $\bm{A}$. The decomposition is written as

\begin{equation}
  \bm{A} = \bm{U} \bm{\Sigma} \bm{V}^T + \text{Error(truncation\_tolerance)},
\end{equation}
where the error is associated to the truncation of the matrices $\bm{U}$ and $\bm{\Sigma}$.\newline

There is one parameter in Kratos, RELATIVE\_SVD. If RELATIVE\_SVD is True, the truncation\_tolerance is multiplied by the norm of the matrix $\bm{A}$. If RELATIVE\_SVD is False, the truncation\_tolerance is the absolute error tolerance. 

\section{Possible collaborations}

1. France Energies Marines. project SUBSEE 4D: development of a digital twin to run offshore floating wind turbine farms. \newline

\url{https://www.france-energies-marines.org/projets/subsee-4d/}\newline


\bibliographystyle{apalike}
\bibliography{references}

\end{document}

